{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this step, we conduct data preprocessing tasks such as imputing missing data and feature engineering. Utilize the `Data_Preprocessing.ipynb` notebook to impute missing values and engineer features that might enhance the predictive model's performance.\n",
    "\n",
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Imputation Methods\n",
    "\n",
    "### 1. PPCA Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPCA_Imputation(df,filename):\n",
    "\n",
    "    # Replace NaN values with the mean for each column\n",
    "    df_filled = df.fillna(df.mean())\n",
    "\n",
    "    # Perform PPCA\n",
    "    num_latent_variables = 2  # You can adjust this based on your analysis\n",
    "    ppca_model = FactorAnalysis(n_components=num_latent_variables)\n",
    "    df_transformed = ppca_model.fit_transform(df_filled)\n",
    "\n",
    "    # Transform the imputed data back to the original space\n",
    "    df_imputed = pd.DataFrame(np.dot(df_transformed, ppca_model.components_) + ppca_model.mean_, columns=df.columns, index=df.index)\n",
    "\n",
    "    df_result=df.combine_first(df_imputed)\n",
    "\n",
    "    # Specifying the file path where you want to save the CSV file\n",
    "    directory=\"./Datasets/With Imputation/PPCA Imputation\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    csv_file_path = directory+f'/{filename}_PPCA.csv'\n",
    "\n",
    "    # Writing the DataFrame to a CSV file\n",
    "    df_result.to_csv(csv_file_path)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extratree Regressor Using Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_reg(df,filename):   \n",
    " \n",
    "    imputer = IterativeImputer(estimator=ExtraTreesRegressor(n_jobs=1),max_iter=10)\n",
    "    df_et=imputer.fit_transform(df) # Fitted the imputer to the data and transformed it\n",
    "    df_et =pd.DataFrame(df_et, columns=df.columns) \n",
    "    df_et.index=df.index\n",
    "    \n",
    "    # Specifying the file path where you want to save the CSV file\n",
    "    directory=\"./Datasets/With Imputation/ET_Regressor Imputation\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    csv_file_path = directory+f'/{filename}_ET.csv'\n",
    "    \n",
    "    # Writing the DataFrame to a CSV file\n",
    "    df_et.to_csv(csv_file_path)\n",
    "\n",
    "    return df_et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_impute(df,filename):   \n",
    " \n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_mean = imputer.fit_transform(df)\n",
    "    df_mean =pd.DataFrame(df_mean, columns=df.columns) \n",
    "    df_mean.index=df.index\n",
    "\n",
    "    # Specifying the file path where you want to save the CSV file\n",
    "    directory=\"./Datasets/With Imputation/Mean Imputation\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    csv_file_path = directory+f'/{filename}_Mean.csv'\n",
    "\n",
    "    # Writing the DataFrame to a CSV file\n",
    "    df_mean.to_csv(csv_file_path)\n",
    "\n",
    "    return df_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_impute(df,filename):    \n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df_median = imputer.fit_transform(df)\n",
    "    df_median =pd.DataFrame(df_median, columns=df.columns) \n",
    "    df_median.index=df.index\n",
    "\n",
    "    # Specifying the file path where you want to save the CSV file\n",
    "    directory=\"./Datasets/With Imputation/Median Imputation\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    csv_file_path = directory+f'/{filename}_Median.csv'\n",
    "\n",
    "    # Writing the DataFrame to a CSV file\n",
    "    df_median.to_csv(csv_file_path)\n",
    "\n",
    "    return df_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Backfill Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfill_impute(df,filename):\n",
    "    df_bfill=df.fillna(method='bfill')\n",
    "\n",
    "    # Specifying the file path where you want to save the CSV file\n",
    "    directory=\"./Datasets/With Imputation/Back Fill Imputation\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    csv_file_path = directory+f'/{filename}_Back_Fill.csv'\n",
    "\n",
    "    # Writing the DataFrame to a CSV file\n",
    "    df_bfill.to_csv(csv_file_path)\n",
    "\n",
    "    return df_bfill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Forwardfill Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill_impute(df,filename):\n",
    "    df_ffill=df.fillna(method='ffill')\n",
    "\n",
    "    # Specifying the file path where you want to save the CSV file\n",
    "    directory=\"./Datasets/With Imputation/Forward Fill Imputation\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    csv_file_path = directory+f'/{filename}_Forward_Fill.csv'\n",
    "\n",
    "    # Writing the DataFrame to a CSV file\n",
    "    df_ffill.to_csv(csv_file_path)\n",
    "\n",
    "    return df_ffill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Imputed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(filepath,filename,imputation=\"PPCA\"):\n",
    "\n",
    "    df = pd.read_csv(filepath,na_values='None')\n",
    "\n",
    "    # Set the Date Time column as the index\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "\n",
    "    if imputation==\"PPCA\":\n",
    "        df=PPCA_Imputation(df,filename)\n",
    "    \n",
    "    elif imputation==\"ET_Regressor\":\n",
    "        df=et_reg(df,filename)\n",
    "    \n",
    "    elif imputation==\"Mean\":\n",
    "        df=mean_impute(df,filename)\n",
    "    \n",
    "    elif imputation==\"Median\":\n",
    "        df=median_impute(df,filename)\n",
    "    \n",
    "    elif imputation==\"BFill\":\n",
    "        df=bfill_impute(df,filename)\n",
    "    \n",
    "    elif imputation==\"FFill\":\n",
    "        df=ffill_impute(df,filename)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_factor_analysis.py:293: ConvergenceWarning: FactorAnalysis did not converge. You might want to increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>WS</th>\n",
       "      <th>WD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.00000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "      <td>33217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>124.629377</td>\n",
       "      <td>248.149939</td>\n",
       "      <td>23.261935</td>\n",
       "      <td>55.323391</td>\n",
       "      <td>45.764546</td>\n",
       "      <td>39.957938</td>\n",
       "      <td>20.498369</td>\n",
       "      <td>1.473976</td>\n",
       "      <td>42.04900</td>\n",
       "      <td>3.335691</td>\n",
       "      <td>25.111851</td>\n",
       "      <td>29.119051</td>\n",
       "      <td>66.443967</td>\n",
       "      <td>1.705485</td>\n",
       "      <td>163.729579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>123.484154</td>\n",
       "      <td>169.218485</td>\n",
       "      <td>53.985440</td>\n",
       "      <td>41.298640</td>\n",
       "      <td>56.168605</td>\n",
       "      <td>20.441260</td>\n",
       "      <td>23.141897</td>\n",
       "      <td>1.353074</td>\n",
       "      <td>35.97178</td>\n",
       "      <td>3.646394</td>\n",
       "      <td>21.510822</td>\n",
       "      <td>2.709916</td>\n",
       "      <td>18.374013</td>\n",
       "      <td>3.429617</td>\n",
       "      <td>90.433769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-20.039319</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.500000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>24.520000</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>15.83000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>108.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>47.400000</td>\n",
       "      <td>27.570000</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>13.150000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>31.75000</td>\n",
       "      <td>2.632402</td>\n",
       "      <td>22.120000</td>\n",
       "      <td>29.680000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>164.321124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161.750000</td>\n",
       "      <td>324.500000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>53.300000</td>\n",
       "      <td>48.650000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>54.92000</td>\n",
       "      <td>4.248627</td>\n",
       "      <td>31.580000</td>\n",
       "      <td>30.880000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>240.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>995.000000</td>\n",
       "      <td>999.250000</td>\n",
       "      <td>496.400000</td>\n",
       "      <td>463.550000</td>\n",
       "      <td>498.500000</td>\n",
       "      <td>462.400000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>15.420000</td>\n",
       "      <td>199.60000</td>\n",
       "      <td>238.530000</td>\n",
       "      <td>305.570000</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>354.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PM2.5          PM10            NO           NO2           NOx  \\\n",
       "count  33217.000000  33217.000000  33217.000000  33217.000000  33217.000000   \n",
       "mean     124.629377    248.149939     23.261935     55.323391     45.764546   \n",
       "std      123.484154    169.218485     53.985440     41.298640     56.168605   \n",
       "min        0.250000      3.000000    -20.039319      0.030000      0.000000   \n",
       "25%       43.500000    125.000000      1.880000     24.520000     13.530000   \n",
       "50%       83.000000    214.000000      4.450000     47.400000     27.570000   \n",
       "75%      161.750000    324.500000     16.300000     75.400000     53.300000   \n",
       "max      995.000000    999.250000    496.400000    463.550000    498.500000   \n",
       "\n",
       "                NH3           SO2            CO        Ozone       Benzene  \\\n",
       "count  33217.000000  33217.000000  33217.000000  33217.00000  33217.000000   \n",
       "mean      39.957938     20.498369      1.473976     42.04900      3.335691   \n",
       "std       20.441260     23.141897      1.353074     35.97178      3.646394   \n",
       "min        0.030000      0.100000      0.000000      0.10000      0.000000   \n",
       "25%       27.300000      6.700000      0.710000     15.83000      0.950000   \n",
       "50%       37.800000     13.150000      1.070000     31.75000      2.632402   \n",
       "75%       48.650000     24.000000      1.660000     54.92000      4.248627   \n",
       "max      462.400000    200.000000     15.420000    199.60000    238.530000   \n",
       "\n",
       "            Toluene          Temp            RH            WS            WD  \n",
       "count  33217.000000  33217.000000  33217.000000  33217.000000  33217.000000  \n",
       "mean      25.111851     29.119051     66.443967      1.705485    163.729579  \n",
       "std       21.510822      2.709916     18.374013      3.429617     90.433769  \n",
       "min        0.000000     14.500000      7.000000      0.300000      1.000000  \n",
       "25%       10.000000     27.700000     53.500000      0.480000    108.500000  \n",
       "50%       22.120000     29.680000     67.500000      1.180000    164.321124  \n",
       "75%       31.580000     30.880000     81.000000      1.830000    240.250000  \n",
       "max      305.570000     59.750000    100.000000     50.000000    354.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=preprocess_csv(\".\\Datasets\\Without Imputation\\Final_Dataset_Ghaziabad.csv\",\"Ghaziabad\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets\\Without Imputation\\Final_Dataset_Aotizhongxin.csv\n",
      "Datasets\\Without Imputation\\Final_Dataset_Ghaziabad.csv\n"
     ]
    }
   ],
   "source": [
    "# Directory containing your CSV files\n",
    "directory = 'Datasets\\Without Imputation'\n",
    "\n",
    "filepaths=[]\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Call the preprocessing function with the file path\n",
    "        filepaths.append(file_path)\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
